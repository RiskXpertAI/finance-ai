import asyncio
import logging
import openai

from app.database import generated_texts_collection  # MongoDB ì—°ê²°
from app.config import OPENAI_API_KEY  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°

# âœ… OpenAI API ì„¤ì •
client = openai.OpenAI(api_key=OPENAI_API_KEY)  # OpenAI API í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


# INFO ë ˆë²¨ ì´ìƒì˜ ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ê³ , ì‹œê°„/ë ˆë²¨/ë©”ì‹œì§€ë¥¼ í¬í•¨í•˜ëŠ” ë¡œê·¸ í¬ë§· ì„¤ì •

# âœ… OpenAI API ìš”ì²­ í•¨ìˆ˜
async def get_openai_response(prompt: str):
    """
    OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸(prompt)ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.

    Args:
        prompt (str): ì‚¬ìš©ìê°€ ì…ë ¥í•œ í”„ë¡¬í”„íŠ¸ (ì§ˆë¬¸ ë˜ëŠ” ìš”ì²­).

    Returns:
        str: OpenAIì—ì„œ ìƒì„±í•œ ì‘ë‹µ í…ìŠ¤íŠ¸.
    """
    logging.info(f"ğŸ”µ OpenAI API ìš”ì²­ ì‹œì‘: {prompt}")  # API ìš”ì²­ ë¡œê·¸ ê¸°ë¡

    loop = asyncio.get_running_loop()  # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ê°€ì ¸ì˜¤ê¸°
    response = await loop.run_in_executor(None, lambda: client.chat.completions.create(
        model="gpt-3.5-turbo",  # ì‚¬ìš©í•  GPT ëª¨ë¸ (gpt-3.5-turbo)
        messages=[{"role": "user", "content": prompt}],  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í¬í•¨í•œ ëŒ€í™” ê¸°ë¡
        max_tokens=150,  # ìµœëŒ€ í† í° ìˆ˜ (150 í† í°ê¹Œì§€ ìƒì„±)
    ))

    logging.info(f"ğŸŸ¢ OpenAI API ì›ë³¸ ì‘ë‹µ: {response}")  # API ì›ë³¸ ì‘ë‹µ ë¡œê·¸ ê¸°ë¡
    generated_text = response.choices[0].message.content.strip()  # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ ë° ê³µë°± ì œê±°
    logging.info(f"ğŸŸ¢ OpenAI API ìµœì¢… ì‘ë‹µ: {generated_text}")  # ìµœì¢… ì‘ë‹µ ë¡œê·¸ ê¸°ë¡

    return generated_text  # OpenAIê°€ ìƒì„±í•œ ì‘ë‹µ ë°˜í™˜


# âœ… MongoDBì— í…ìŠ¤íŠ¸ ì €ì¥
async def save_generated_text(prompt: str, generated_text: str):
    """
    ì‚¬ìš©ìì˜ í”„ë¡¬í”„íŠ¸ì™€ OpenAIì—ì„œ ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ MongoDBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜.

    Args:
        prompt (str): ì‚¬ìš©ìê°€ ì…ë ¥í•œ í”„ë¡¬í”„íŠ¸.
        generated_text (str): OpenAIê°€ ìƒì„±í•œ ì‘ë‹µ í…ìŠ¤íŠ¸.

    Returns:
        ObjectId: ì €ì¥ëœ ë¬¸ì„œì˜ MongoDB ObjectId.
    """
    logging.info(f"ğŸ’¾ MongoDBì— ë°ì´í„° ì €ì¥: {prompt} -> {generated_text}")  # ì €ì¥ ì‘ì—… ë¡œê·¸ ê¸°ë¡
    document = {"prompt": prompt, "generated_text": generated_text}  # ì €ì¥í•  ë¬¸ì„œ ìƒì„±
    result = await generated_texts_collection.insert_one(document)  # MongoDBì— ë¬¸ì„œ ì €ì¥ (ë¹„ë™ê¸° ì‹¤í–‰)
    return result.inserted_id  # ì €ì¥ëœ ë¬¸ì„œì˜ ObjectId ë°˜í™˜


# âœ… MongoDBì—ì„œ ê°€ì¥ ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
async def get_stored_text():
    """
    MongoDBì—ì„œ ê°€ì¥ ìµœê·¼ì— ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ ë° ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.

    Returns:
        dict or None: ê°€ì¥ ìµœì‹ ì˜ ë¬¸ì„œ ë°˜í™˜ (ì—†ìœ¼ë©´ None ë°˜í™˜).
    """
    logging.info("ğŸ“¥ MongoDBì—ì„œ ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°")  # ë°ì´í„° ì¡°íšŒ ë¡œê·¸ ê¸°ë¡
    document = await generated_texts_collection.find_one(sort=[('_id', -1)])  # ìµœì‹  ë°ì´í„° 1ê°œ ê°€ì ¸ì˜¤ê¸°
    if not document:
        logging.warning("âš ï¸ MongoDBì— ë°ì´í„°ê°€ ì—†ìŒ!")  # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê²½ê³  ë¡œê·¸ ì¶œë ¥
    return document  # ê°€ì ¸ì˜¨ ë¬¸ì„œ ë°˜í™˜ (ì—†ìœ¼ë©´ None)


# í”„ë¡¬í¬íŠ¸ ìƒì„±í•¨ìˆ˜
def build_forecast_prompt(user_input: str, forecast: dict):
    forecast_text = f"""
3ê°œì›” í›„ ì£¼ìš” ì§€í‘œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
- GDP: {forecast['GDP']:.3f}
- í™˜ìœ¨: {forecast['í™˜ìœ¨']:.2f}
- ìƒì‚°ìë¬¼ê°€ì§€ìˆ˜: {forecast['ìƒì‚°ìë¬¼ê°€ì§€ìˆ˜']:.2f}
- ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜: {forecast['ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜']:.2f}
- ê¸ˆë¦¬: {forecast['ê¸ˆë¦¬']:.2f}
"""
    prompt = f"""
```{forecast_text}```

[Note]
1. SummaryëŠ” 400ê¸€ì ë‚´ì™¸ë¡œ ì‘ì„±.
2. SummaryëŠ” {{\\n}}ì„ í¬í•¨í•  ìˆ˜ ì—†ë‹¤.

ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•˜ë©° ë‹¤ìŒ ì–‘ì‹ì„ ë”°ë¥¸ë‹¤:

Summary: {{```ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ê¸€ì˜ ìš”ì•½}}

ì‚¬ìš©ì ì§ˆë¬¸: {user_input}
"""
    return prompt


# ìƒˆë¡œìš´ í•¨ìˆ˜ë¡œ GPT-2 ì‘ë‹µì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •
async def get_scenario_based_answer(prompt: str):

    logging.info(f"ğŸ”µ GPT-2 API ìš”ì²­ ì‹œì‘: {prompt}")  # API ìš”ì²­ ë¡œê·¸ ê¸°ë¡

    loop = asyncio.get_running_loop()  # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ê°€ì ¸ì˜¤ê¸°
    response = await loop.run_in_executor(None, lambda: client.chat.completions.create(
        model="gpt-3.5-turbo",  # ì‚¬ìš©í•  GPT ëª¨ë¸
        messages=[{"role": "user", "content": prompt}],  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í¬í•¨í•œ ëŒ€í™” ê¸°ë¡
        max_tokens=300,  # ìµœëŒ€ í† í° ìˆ˜ (ìƒí™©ì— ë”°ë¼ ëŠ˜ë¦´ ìˆ˜ ìˆìŒ)
    ))

    logging.info(f"ğŸŸ¢ GPT-2 API ì›ë³¸ ì‘ë‹µ: {response}")  # API ì›ë³¸ ì‘ë‹µ ë¡œê·¸ ê¸°ë¡
    generated_text = response.choices[0].message.content.strip()  # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ ë° ê³µë°± ì œê±°
    logging.info(f"ğŸŸ¢ GPT-2 API ìµœì¢… ì‘ë‹µ: {generated_text}")  # ìµœì¢… ì‘ë‹µ ë¡œê·¸ ê¸°ë¡

    return generated_text  # GPT-2ê°€ ìƒì„±í•œ ì‘ë‹µ ë°˜í™˜
import asyncio
import logging

from transformers import pipeline
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_community.llms import OpenAI
import openai

from app.database import collection  # MongoDB ì—°ê²°
from app.config import OPENAI_API_KEY

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = OPENAI_API_KEY

# Hugging Face ëª¨ë¸ ë¡œë“œ (ë™ê¸° ì‹¤í–‰)
generator = pipeline('text-generation', model='gpt2')

# ë¹„ë™ê¸°ë¡œ Hugging Face ëª¨ë¸ ì‹¤í–‰
async def generate_text(prompt: str):
    loop = asyncio.get_running_loop()
    generated_text = await loop.run_in_executor(None, lambda: generator(prompt, max_length=200, truncation=True))
    return generated_text[0]['generated_text']

# OpenAI API ë¹„ë™ê¸° í˜¸ì¶œ
async def get_openai_response(prompt: str):
    logging.info(f"ğŸ”µ OpenAI API ìš”ì²­ ì‹œì‘: {prompt}")  # ìš”ì²­ ë¡œê·¸ ì°ê¸°

    loop = asyncio.get_running_loop()
    response = await loop.run_in_executor(None, lambda: openai.Completion.create(
        model="text-davinci-003",
        prompt=prompt,
        max_tokens=150,
    ))

    logging.info(f"ğŸŸ¢ OpenAI ì›ë³¸ ì‘ë‹µ: {response}")  # ì‘ë‹µ ì›ë³¸ì„ ë¡œê·¸ì— ì¶œë ¥

    generated_text = response.choices[0].text.strip()
    logging.info(f"ğŸŸ¢ OpenAI API ì‘ë‹µ ë°›ìŒ: {generated_text}")  # ê°€ê³µëœ ì‘ë‹µ ë¡œê·¸ ì°ê¸°

    return generated_text


# MongoDBì— í…ìŠ¤íŠ¸ ì €ì¥
async def save_generated_text(prompt: str, generated_text: str):
    document = {"prompt": prompt, "generated_text": generated_text}
    result = await collection.insert_one(document)
    return result.inserted_id

# MongoDBì—ì„œ ê°€ì¥ ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
async def get_stored_text():
    document = await collection.find_one(sort=[('_id', -1)])
    return document

# LangChainì„ ì‚¬ìš©í•œ ì¶”ê°€ ë¶„ì„
async def process_with_langchain():
    document = await get_stored_text()
    if not document:
        return "No data found in MongoDB"

    generated_text = document["generated_text"]

    # LangChain ì„¤ì •
    prompt_template = "Given the following prompt, summarize or generate more information: {generated_text}"
    prompt_obj = PromptTemplate(input_variables=["generated_text"], template=prompt_template)

    llm = OpenAI(model_name="text-davinci-003", openai_api_key=OPENAI_API_KEY)
    llm_chain = LLMChain(prompt=prompt_obj, llm=llm)

    result = await llm_chain.arun(generated_text)
    return result
